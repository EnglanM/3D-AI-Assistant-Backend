# Talking Avatar backend for this [Frontend](https://github.com/EnglanM/3D-AI-Assistant-Frontend)
The text to speech, OpenAi API and blendShapes converter for the talking avatar.
Uses the [Azure APIs](https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-speech-synthesis-viseme) to get stuff done. For AI I have used [OpenAi API](https://platform.openai.com/docs/api-reference/introduction)

This is a simple ExpressJS app.

### Get keys from Azure and create a `.env` in the root directory with
```
AZURE_KEY=
AZURE_REGION=
```
### To run
```
$ npm install
$ npm start
```

